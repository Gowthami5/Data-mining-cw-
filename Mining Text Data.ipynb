{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "353bab5f",
   "metadata": {},
   "source": [
    "### 3 Mining Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6710334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caefc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa059d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a pandas dataframe containing the data set.\n",
    "# Specify a 'latin-1' encoding when reading the data.\n",
    "# data_file will be populated with the string 'wholesale_customers.csv'.\n",
    "def read_csv_3(data_file):\n",
    "    \n",
    "    df = pd.read_csv(data_file,index_col=False, encoding = 'latin-1')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b19d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list with the possible sentiments that a tweet might have.\n",
    "def get_sentiments(df):\n",
    "    \n",
    "    sentiments = df['Sentiment'].unique().tolist() \n",
    "        \n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6116478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a string containing the second most popular sentiment among the tweets.\n",
    "def second_most_popular_sentiment(df):\n",
    "    \n",
    "  \n",
    "    total_Counts = df.groupby('Sentiment')['Sentiment'].count().reset_index(name='Count')\\\n",
    "                    .sort_values(['Count'], ascending=False).reset_index(drop=True)\n",
    "    # print(total_Counts)\n",
    "    \n",
    "    second = total_Counts['Sentiment'][1]\n",
    "    \n",
    "    return second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99e6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the date (string as it appears in the data) with the greatest number of extremely positive tweets.\n",
    "def date_most_popular_tweets(df):\n",
    "    \n",
    "    total_Counts = df.groupby(['TweetAt','Sentiment'])['TweetAt'].count().reset_index(name='Count')\\\n",
    "                    .sort_values(['Count'], ascending=False).reset_index(drop=True)\n",
    "    # print(total_Counts)\n",
    "    \n",
    "    # date  = total_Counts[['TweetAt', 'Sentiment', 'Count']][total_Counts['Sentiment'] == 'Positive'].reset_index(drop=True)\n",
    "    date  = total_Counts['TweetAt'][total_Counts['Sentiment'] == 'Positive'].reset_index(drop=True)[0]\n",
    "    \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475f07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the dataframe df by converting all tweets to lower case. \n",
    "def lower_case(df):\n",
    "    \n",
    "    df['OriginalTweet'] = df['OriginalTweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c20ff734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the dataframe df by replacing each characters which is not alphabetic or whitespace with a whitespace.\n",
    "def remove_non_alphabetic_chars(df):\n",
    "    \n",
    "    df['OriginalTweet'] = df['OriginalTweet'].str.replace(r'[^a-zA-Z]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df57755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the dataframe df with tweets after removing characters which are not alphabetic or whitespaces.\n",
    "def remove_multiple_consecutive_whitespaces(df):\n",
    "    \n",
    "    df['OriginalTweet'] = df['OriginalTweet'].replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d5e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataframe where each tweet is one string with words separated by single whitespaces,\n",
    "# tokenize every tweet by converting it into a list of words (strings).\n",
    "def tokenize(df):\n",
    "    \n",
    "    df['OriginalTweet'] = df.apply(lambda row: nltk.word_tokenize(row['OriginalTweet']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3710c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given dataframe tdf with the tweets tokenized, return the number of words in all tweets including repetitions.\n",
    "def count_words_with_repetitions(tdf):\n",
    "\n",
    "    count_words = tdf['OriginalTweet'].str.len().sum()\n",
    "    \n",
    "    return count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59bd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given dataframe tdf with the tweets tokenized, return the number of distinct words in all tweets.\n",
    "def count_words_without_repetitions(tdf):\n",
    "    \n",
    "    count_words = sum(tdf['OriginalTweet'].apply(set).apply(len))\n",
    "    \n",
    "    return count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93c11191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given dataframe tdf with the tweets tokenized, return a list with the k distinct words that are most frequent in the tweets.\n",
    "def frequent_words(tdf,k):\n",
    "    \n",
    "    split_it = ''.join([' '.join(wrd for wrd in x) for x in tdf['OriginalTweet']]).split()\n",
    "    Count = Counter(split_it)\n",
    "    most_occur = Count.most_common(k)\n",
    "    \n",
    "    return [most_occur[x][0] for x in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "713ea292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given dataframe tdf with the tweets tokenized, remove stop words and words with <=2 characters from each tweet.\n",
    "# The function should download the list of stop words via:\n",
    "# https://raw.githubusercontent.com/fozziethebeat/S-Space/master/data/english-stop-words-large.txt\n",
    "def remove_stop_words(tdf):\n",
    "    \n",
    "    x = requests.get('https://raw.githubusercontent.com/fozziethebeat/S-Space/master/data/english-stop-words-large.txt')\n",
    "    stopWords = (x.text).strip('][').split('\\n')\n",
    "          \n",
    "    tdf['OriginalTweet'] = tdf['OriginalTweet'].apply(lambda x: \\\n",
    "                            [word for word in x if (word not in (stopWords) and len(word)>2)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6c486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cbda6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given dataframe tdf with the tweets tokenized, reduce each word in every tweet to its stem.\n",
    "def stemming(tdf):\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    tdf['OriginalTweet'] = tdf['OriginalTweet'].apply(lambda x: \\\n",
    "                            [ps.stem(word) for word in x])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3bc2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a pandas dataframe df with the original coronavirus_tweets.csv data set,\n",
    "# build a Multinomial Naive Bayes classifier. \n",
    "# Return predicted sentiments (e.g. 'Neutral', 'Positive') for the training set\n",
    "# as a 1d array (numpy.ndarray). \n",
    "def mnb_predict(df):\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b02126f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a 1d array (numpy.ndarray) y_pred with predicted labels (e.g. 'Neutral', 'Positive') \n",
    "# by a classifier and another 1d array y_true with the true labels, \n",
    "# return the classification accuracy rounded in the 3rd decimal digit.\n",
    "def mnb_accuracy(y_pred,y_true):\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d09361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335ee96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b970df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f85107e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17076fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6dd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdee1434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1. Possible sentiments that a tweet may have: \n",
      "['Neutral', 'Positive', 'Extremely Negative', 'Negative', 'Extremely Positive']\n",
      "1.2. The second most popular sentiment in the tweets: \n",
      "Negative\n",
      "1.3. The date with the greatest number of extremely positive tweets: \n",
      "20-03-2020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>menyrbie phil gahan chrisitv https t co ifz f...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>me ready to go at supermarket during the covid...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0   menyrbie phil gahan chrisitv https t co ifz f...             Neutral  \n",
       "1  advice talk to your neighbours family to excha...            Positive  \n",
       "2  coronavirus australia woolworths to give elder...            Positive  \n",
       "3  my food stock is not the only one which is emp...            Positive  \n",
       "4  me ready to go at supermarket during the covid...  Extremely Negative  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. [13 points] Compute the possible sentiments that a tweet may have, the second most popular\n",
    "# sentiment in the tweets, and the date with the greatest number of extremely positive tweets.\n",
    "# Next, convert the messages to lower case, replace non-alphabetical characters with whitespaces\n",
    "# and ensure that the words of a message are separated by a single whitespace.\n",
    "\n",
    "# Read data \n",
    "df = read_csv_3('Corona_NLP_train.csv')\n",
    "df.head()\n",
    "\n",
    "# possible sentiments that a tweet may have\n",
    "print('1.1. Possible sentiments that a tweet may have: ')\n",
    "sentiments = get_sentiments(df)\n",
    "print(sentiments)\n",
    "\n",
    "# the second most popular sentiment in the tweets\n",
    "print('1.2. The second most popular sentiment in the tweets: ')\n",
    "second_sentiment = second_most_popular_sentiment(df)\n",
    "print(second_sentiment)\n",
    "\n",
    "# the date with the greatest number of extremely positive tweets\n",
    "print('1.3. The date with the greatest number of extremely positive tweets: ')\n",
    "date_tweets = date_most_popular_tweets(df)\n",
    "print(date_tweets)\n",
    "\n",
    "# convert the messages to lower case\n",
    "lower_case(df)\n",
    "\n",
    "# replace non-alphabetical characters with whitespaces\n",
    "remove_non_alphabetic_chars(df)\n",
    "\n",
    "# ensure that the words of a message are separated by a single whitespace.\n",
    "remove_multiple_consecutive_whitespaces(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd9ad232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[menyrbie, phil, gahan, chrisitv, https, t, co...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[advice, talk, to, your, neighbours, family, t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[coronavirus, australia, woolworths, to, give,...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[my, food, stock, is, not, the, only, one, whi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>[me, ready, to, go, at, supermarket, during, t...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  [menyrbie, phil, gahan, chrisitv, https, t, co...             Neutral  \n",
       "1  [advice, talk, to, your, neighbours, family, t...            Positive  \n",
       "2  [coronavirus, australia, woolworths, to, give,...            Positive  \n",
       "3  [my, food, stock, is, not, the, only, one, whi...            Positive  \n",
       "4  [me, ready, to, go, at, supermarket, during, t...  Extremely Negative  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. [14 points] Tokenize the tweets (i.e. convert each into a list of words), count the total number\n",
    "# of all words (including repetitions), the number of all distinct words and the 10 most frequent\n",
    "# words in the corpus. Remove stop words, words with ≤ 2 characters, and reduce each word to\n",
    "# its stem. You are now able to recompute the 10 most frequent words in the modified corpus.\n",
    "# What do you observe?\n",
    "\n",
    "# Tokenize the tweets \n",
    "tokenize(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88634161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1351476\n",
      "1207314\n",
      "['the', 'to', 't', 'co', 'and']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41147</th>\n",
       "      <td>44946</td>\n",
       "      <td>89898</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[shitting, home, covid, coronavirus, toiletpaper]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41148</th>\n",
       "      <td>44947</td>\n",
       "      <td>89899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[light, sterilizer, sanitizer, mask, mobile, p...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41149</th>\n",
       "      <td>44948</td>\n",
       "      <td>89900</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[shocked, number, toronto, supermarket, employ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41150</th>\n",
       "      <td>44949</td>\n",
       "      <td>89901</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[situation, amp, world, supermarket, picking, ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41151</th>\n",
       "      <td>44950</td>\n",
       "      <td>89902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[mrsilverscott, man, feel, fall, honor, heroes...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[airline, pilots, offering, stock, supermarket...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[response, complaint, provided, citing, covid,...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[tough, kameronwilds, rationing, toilet, paper...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[wrong, smell, hand, sanitizer, starting, turn...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>[tartiicat, rift, amazon, normal, market, pric...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "41147     44946       89898                  Brooklyn, NY  14-04-2020   \n",
       "41148     44947       89899                           NaN  14-04-2020   \n",
       "41149     44948       89900              Toronto, Ontario  14-04-2020   \n",
       "41150     44949       89901                          OHIO  14-04-2020   \n",
       "41151     44950       89902                           NaN  14-04-2020   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "41147  [shitting, home, covid, coronavirus, toiletpaper]            Negative  \n",
       "41148  [light, sterilizer, sanitizer, mask, mobile, p...  Extremely Positive  \n",
       "41149  [shocked, number, toronto, supermarket, employ...            Negative  \n",
       "41150  [situation, amp, world, supermarket, picking, ...            Positive  \n",
       "41151  [mrsilverscott, man, feel, fall, honor, heroes...  Extremely Positive  \n",
       "41152  [airline, pilots, offering, stock, supermarket...             Neutral  \n",
       "41153  [response, complaint, provided, citing, covid,...  Extremely Negative  \n",
       "41154  [tough, kameronwilds, rationing, toilet, paper...            Positive  \n",
       "41155  [wrong, smell, hand, sanitizer, starting, turn...             Neutral  \n",
       "41156  [tartiicat, rift, amazon, normal, market, pric...            Negative  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the total number of all words\n",
    "print('2.1. Total number of all words: ')\n",
    "count_words = count_words_with_repetitions(df)\n",
    "print(count_words)\n",
    "\n",
    "# the number of all distinct words\n",
    "print('2.2. Total number of all distinct words: ')\n",
    "count_words = count_words_without_repetitions(df)\n",
    "print(count_words)\n",
    "\n",
    "# 10 most frequent words\n",
    "print('2.3. Most frequent words: ')\n",
    "freq_word = frequent_words(df,10)\n",
    "print(freq_word)\n",
    "\n",
    "remove_stop_words(df)\n",
    "df.head()\n",
    "\n",
    "stemming(df)\n",
    "df.head()\n",
    "\n",
    "# 10 most frequent words\n",
    "print('2.4. Most frequent words after stop words and stemming: ')\n",
    "freq_word = frequent_words(df,10)\n",
    "print(freq_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8379a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [13 points] This task can be done individually from the previous three. \n",
    "# Store the coronavirus tweets.py corpus in a numpy array and produce a sparse representation of \n",
    "# the term document matrix with a CountVectorizer. Next, produce a Multinomial Naive Bayes classifier\n",
    "# using the provided data set. What is the classifier’s training accuracy? A CountVectorizer allows\n",
    "# limiting the range of frequencies and number of words included in the term-document matrix.\n",
    "# Appropriately tune these parameters to achieve the highest classification accuracy you can.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5399989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
